{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN5nYeE18QyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S246Hy3P8p-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls /content/gdrive/My\\ Drive/cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWDkz0etiDZh",
        "colab_type": "code",
        "outputId": "f3f8bcc8-7e5a-420e-9112-956212384a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD-bOILV7Gzr",
        "colab_type": "code",
        "outputId": "85d533fb-0e5a-4ac4-fa55-6fa27d8ce725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.15.0\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import metrics, callbacks\n",
        "\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "\n",
        "\n",
        "# setting\n",
        "base_name = 'cifar_cnn'\n",
        "epoch = 50\n",
        "learning_rate = 0.0001\n",
        "activation1 = 'relu'\n",
        "activation2 = 'softmax'\n",
        "optimizer = keras.optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
        "# optimizer = keras.optimizers.RMSprop(lr=learning_rate, decay=1e-6)\n",
        "optimizer_name = 'Adam'\n",
        "dropout = 0.40\n",
        "\n",
        "logging.basicConfig(filename='/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}.log'.format(\n",
        "                                base_name, epoch, learning_rate, activation1, optimizer_name, dropout),\n",
        "                    level=logging.DEBUG,\n",
        "                    format='[%(asctime)s] %(name)s %(levelname)s \\n%(message)s'\n",
        "                    )\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "logger.info(\"-------------------- Learning Settings --------------------\")\n",
        "logger.info('epoch = {}'.format(epoch))\n",
        "logger.info('learning_rate = {}'.format(learning_rate))\n",
        "logger.info('activation_functions = {}, {}'.format(activation1, activation2))\n",
        "logger.info('optimizer = {}'.format(optimizer_name))\n",
        "logger.info('dropout = {}'.format(dropout))\n",
        "logger.info(\"-------------------- Start training! --------------------\")\n",
        "\n",
        "# 데이터 변수 선언\n",
        "num_classes = 10\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "in_shape = (im_rows, im_cols, 3)\n",
        "im_size = im_rows * im_cols * 3\n",
        "\n",
        "# (1) 데이터 읽어 들이기 -----------------------------------\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "logger.info('-------------------- cifar10.load_data() --------------------')\n",
        "\n",
        "# (2) 데이터가공 ------------------------------------------\n",
        "# 3차원 변환 및 정규화\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "logger.info('-------------------- Reshaping. --------------------')\n",
        "\n",
        "# 레이블 데이터를 One-hot 형식으로 변환\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "logger.info('-------------------- One-hot Encoding. --------------------')\n",
        "\n",
        "\n",
        "# CNN 모델 정의하기\n",
        "model = Sequential()\n",
        "\n",
        "# convolution layers - 특징 맵 추출\n",
        "# polling layers - 특징 맵 축소 최대폴링/평균폴링\n",
        "# fully connected layers - 각 레이어 결합. 2차원 특징맵을 1차원으로 전개\n",
        "# activation function - 특징 강조\n",
        "# output layer - 출력 레이어\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=in_shape))\n",
        "model.add(Activation(activation1))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation(activation1))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation(activation1))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Flatten())    # 3차원 -> 1차원\n",
        "model.add(Dense(512))   # Dense가 1차원밖에 못 받음\n",
        "model.add(Activation(activation1))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(activation1))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(activation2))\n",
        "logger.info('-------------------- Define CNN model --------------------')\n",
        "# model.summary()\n",
        "logger.info(model.summary())\n",
        "\n",
        "# 모델 생성\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', metrics.categorical_accuracy]\n",
        ")\n",
        "logger.info('-------------------- model.compile() --------------------')\n",
        "\n",
        "# 학습 실행하기\n",
        "# 전체 데이터 반복 횟수 epochs => 50\n",
        "# 전체 데이터 1회 반복 시 학습 데이터 크기 32\n",
        "# validation_data => 각 epoch마다 검증 데이터 정확도 출력\n",
        "# validation_split => 데이터셋 비율\n",
        "logger.info(\"-------------------- Start model.fit() --------------------\")\n",
        "\n",
        "hist = model.fit(X_train, y_train,\n",
        "                 batch_size=32,\n",
        "                 epochs=epoch,\n",
        "                 verbose=1,\n",
        "                 validation_data=(X_test, y_test)\n",
        "                 )\n",
        "\n",
        "# 모델 평가하기\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "logger.info('Accuracy: {} / loss: {}'.format(score[1], score[0]))\n",
        "print('정답률=', score[1], ' / loss=', score[0])\n",
        "\n",
        "# 학습 상태를 그래프로 그리기\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "try:\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'accuracy', 'png'))\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'accuracy', 'svg'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "try:\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'loss', 'png'))\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'loss', 'svg'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    model.save_weights('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'h5'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 817,450\n",
            "Trainable params: 817,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 2.0209 - acc: 0.2158 - categorical_accuracy: 0.2158 - val_loss: 1.6968 - val_acc: 0.3836 - val_categorical_accuracy: 0.3836\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.6209 - acc: 0.3862 - categorical_accuracy: 0.3862 - val_loss: 1.4340 - val_acc: 0.4639 - val_categorical_accuracy: 0.4639\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 1.4608 - acc: 0.4604 - categorical_accuracy: 0.4604 - val_loss: 1.3077 - val_acc: 0.5192 - val_categorical_accuracy: 0.5192\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 15s 300us/step - loss: 1.3463 - acc: 0.5049 - categorical_accuracy: 0.5049 - val_loss: 1.2178 - val_acc: 0.5624 - val_categorical_accuracy: 0.5624\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.2621 - acc: 0.5417 - categorical_accuracy: 0.5417 - val_loss: 1.1620 - val_acc: 0.5720 - val_categorical_accuracy: 0.5720\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 15s 296us/step - loss: 1.1983 - acc: 0.5668 - categorical_accuracy: 0.5668 - val_loss: 1.1436 - val_acc: 0.5923 - val_categorical_accuracy: 0.5923\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 1.1514 - acc: 0.5833 - categorical_accuracy: 0.5833 - val_loss: 1.0662 - val_acc: 0.6200 - val_categorical_accuracy: 0.6200\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 15s 291us/step - loss: 1.1061 - acc: 0.6035 - categorical_accuracy: 0.6035 - val_loss: 1.0246 - val_acc: 0.6385 - val_categorical_accuracy: 0.6385\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 1.0592 - acc: 0.6221 - categorical_accuracy: 0.6221 - val_loss: 0.9520 - val_acc: 0.6584 - val_categorical_accuracy: 0.6584\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 15s 296us/step - loss: 1.0222 - acc: 0.6382 - categorical_accuracy: 0.6382 - val_loss: 0.9033 - val_acc: 0.6768 - val_categorical_accuracy: 0.6768\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 15s 290us/step - loss: 0.9894 - acc: 0.6486 - categorical_accuracy: 0.6486 - val_loss: 0.8813 - val_acc: 0.6871 - val_categorical_accuracy: 0.6871\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 14s 288us/step - loss: 0.9553 - acc: 0.6637 - categorical_accuracy: 0.6637 - val_loss: 0.8972 - val_acc: 0.6809 - val_categorical_accuracy: 0.6809\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 0.9236 - acc: 0.6736 - categorical_accuracy: 0.6736 - val_loss: 0.8333 - val_acc: 0.7054 - val_categorical_accuracy: 0.7054\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.8980 - acc: 0.6835 - categorical_accuracy: 0.6835 - val_loss: 0.8023 - val_acc: 0.7176 - val_categorical_accuracy: 0.7176\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.8732 - acc: 0.6911 - categorical_accuracy: 0.6911 - val_loss: 0.7627 - val_acc: 0.7308 - val_categorical_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 15s 293us/step - loss: 0.8456 - acc: 0.7005 - categorical_accuracy: 0.7005 - val_loss: 0.7513 - val_acc: 0.7396 - val_categorical_accuracy: 0.7396\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.8266 - acc: 0.7116 - categorical_accuracy: 0.7116 - val_loss: 0.7408 - val_acc: 0.7423 - val_categorical_accuracy: 0.7423\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 0.8049 - acc: 0.7183 - categorical_accuracy: 0.7183 - val_loss: 0.7091 - val_acc: 0.7530 - val_categorical_accuracy: 0.7530\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.7833 - acc: 0.7257 - categorical_accuracy: 0.7257 - val_loss: 0.7314 - val_acc: 0.7454 - val_categorical_accuracy: 0.7454\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 15s 294us/step - loss: 0.7704 - acc: 0.7306 - categorical_accuracy: 0.7306 - val_loss: 0.7050 - val_acc: 0.7550 - val_categorical_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 0.7581 - acc: 0.7375 - categorical_accuracy: 0.7375 - val_loss: 0.6701 - val_acc: 0.7662 - val_categorical_accuracy: 0.7662\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 0.7382 - acc: 0.7439 - categorical_accuracy: 0.7439 - val_loss: 0.6917 - val_acc: 0.7621 - val_categorical_accuracy: 0.7621\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.7213 - acc: 0.7486 - categorical_accuracy: 0.7486 - val_loss: 0.6650 - val_acc: 0.7702 - val_categorical_accuracy: 0.7702\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.7147 - acc: 0.7537 - categorical_accuracy: 0.7537 - val_loss: 0.6436 - val_acc: 0.7767 - val_categorical_accuracy: 0.7767\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.7037 - acc: 0.7567 - categorical_accuracy: 0.7567 - val_loss: 0.6697 - val_acc: 0.7717 - val_categorical_accuracy: 0.7717\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 0.6867 - acc: 0.7605 - categorical_accuracy: 0.7605 - val_loss: 0.6416 - val_acc: 0.7776 - val_categorical_accuracy: 0.7776\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.6724 - acc: 0.7651 - categorical_accuracy: 0.7651 - val_loss: 0.6295 - val_acc: 0.7819 - val_categorical_accuracy: 0.7819\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 15s 296us/step - loss: 0.6627 - acc: 0.7711 - categorical_accuracy: 0.7711 - val_loss: 0.6347 - val_acc: 0.7881 - val_categorical_accuracy: 0.7881\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.6504 - acc: 0.7751 - categorical_accuracy: 0.7751 - val_loss: 0.6109 - val_acc: 0.7926 - val_categorical_accuracy: 0.7926\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 0.6434 - acc: 0.7778 - categorical_accuracy: 0.7778 - val_loss: 0.6114 - val_acc: 0.7887 - val_categorical_accuracy: 0.7887\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 0.6326 - acc: 0.7800 - categorical_accuracy: 0.7800 - val_loss: 0.6002 - val_acc: 0.7971 - val_categorical_accuracy: 0.7971\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 0.6227 - acc: 0.7831 - categorical_accuracy: 0.7831 - val_loss: 0.6035 - val_acc: 0.7943 - val_categorical_accuracy: 0.7943\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 0.6135 - acc: 0.7878 - categorical_accuracy: 0.7878 - val_loss: 0.5868 - val_acc: 0.7992 - val_categorical_accuracy: 0.7992\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.6095 - acc: 0.7893 - categorical_accuracy: 0.7893 - val_loss: 0.5707 - val_acc: 0.8048 - val_categorical_accuracy: 0.8048\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 14s 288us/step - loss: 0.5970 - acc: 0.7951 - categorical_accuracy: 0.7951 - val_loss: 0.5676 - val_acc: 0.8065 - val_categorical_accuracy: 0.8065\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 14s 288us/step - loss: 0.5932 - acc: 0.7961 - categorical_accuracy: 0.7961 - val_loss: 0.5645 - val_acc: 0.8063 - val_categorical_accuracy: 0.8063\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 15s 292us/step - loss: 0.5840 - acc: 0.7972 - categorical_accuracy: 0.7972 - val_loss: 0.5813 - val_acc: 0.8032 - val_categorical_accuracy: 0.8032\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 15s 293us/step - loss: 0.5762 - acc: 0.8006 - categorical_accuracy: 0.8006 - val_loss: 0.5727 - val_acc: 0.8063 - val_categorical_accuracy: 0.8063\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 15s 295us/step - loss: 0.5729 - acc: 0.8020 - categorical_accuracy: 0.8020 - val_loss: 0.5609 - val_acc: 0.8056 - val_categorical_accuracy: 0.8056\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 15s 296us/step - loss: 0.5619 - acc: 0.8051 - categorical_accuracy: 0.8051 - val_loss: 0.5458 - val_acc: 0.8165 - val_categorical_accuracy: 0.8165\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 15s 300us/step - loss: 0.5631 - acc: 0.8041 - categorical_accuracy: 0.8041 - val_loss: 0.5527 - val_acc: 0.8116 - val_categorical_accuracy: 0.8116\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.5516 - acc: 0.8073 - categorical_accuracy: 0.8073 - val_loss: 0.5548 - val_acc: 0.8078 - val_categorical_accuracy: 0.8078\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 15s 295us/step - loss: 0.5420 - acc: 0.8131 - categorical_accuracy: 0.8131 - val_loss: 0.5479 - val_acc: 0.8126 - val_categorical_accuracy: 0.8126\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.5384 - acc: 0.8137 - categorical_accuracy: 0.8137 - val_loss: 0.5507 - val_acc: 0.8137 - val_categorical_accuracy: 0.8137\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 0.5318 - acc: 0.8151 - categorical_accuracy: 0.8151 - val_loss: 0.5348 - val_acc: 0.8163 - val_categorical_accuracy: 0.8163\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.5298 - acc: 0.8158 - categorical_accuracy: 0.8158 - val_loss: 0.5425 - val_acc: 0.8143 - val_categorical_accuracy: 0.8143\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.5244 - acc: 0.8162 - categorical_accuracy: 0.8162 - val_loss: 0.5418 - val_acc: 0.8176 - val_categorical_accuracy: 0.8176\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 0.5194 - acc: 0.8195 - categorical_accuracy: 0.8195 - val_loss: 0.5463 - val_acc: 0.8166 - val_categorical_accuracy: 0.8166\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.5121 - acc: 0.8218 - categorical_accuracy: 0.8218 - val_loss: 0.5401 - val_acc: 0.8187 - val_categorical_accuracy: 0.8187\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.5036 - acc: 0.8258 - categorical_accuracy: 0.8258 - val_loss: 0.5357 - val_acc: 0.8160 - val_categorical_accuracy: 0.8160\n",
            "10000/10000 [==============================] - 1s 95us/step\n",
            "정답률= 0.816  / loss= 0.5356894411563873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxUVZr/8c+TfV9JQkIIhH2TRSKL\n4goquKC2jqNIt/aGTuuM7dh2a7faoz39G7tn3LrbZdSh3doVN2xpRVTcCEJQkB1CWLIRspB9Tz2/\nP26BCSQkQLaqet6vV72q7r2nqs7F4uvh3HPPEVXFGGOM5/Pr6woYY4zpHhboxhjjJSzQjTHGS1ig\nG2OMl7BAN8YYL2GBbowxXsIC3RhjvIQFuvE4IrJSRA6KSHBf18WY/sQC3XgUERkKnAkoML8Xvzeg\nt77LmBNlgW48zQ+A1cCzwPWHdopIqIg8KCJ7RaRCRL4QkVD3sVkiskpEykUkV0RucO9fKSI/afUZ\nN4jIF622VURuFpGdwE73vkfdn1EpIutE5MxW5f1F5NcisktEqtzHB4vIYyLyYOuTEJGlInJbT/wB\nGd9lgW48zQ+Av7kfF4pIknv//wBTgdOBOOCXgEtEhgD/AP4MJACTgfXH8X2XA9OBce7tte7PiANe\nAl4XkRD3sX8HrgUuAqKAHwG1wHPAtSLiByAiA4A57vcb020s0I3HEJFZwBDgNVVdB+wCFriD8kfA\nraqar6otqrpKVRuABcAKVX1ZVZtUtVRVjyfQ/0tVy1S1DkBVX3R/RrOqPggEA6PdZX8C3K2q29Wx\nwV12DVABzHaXuwZYqapFJ/lHYkwbFujGk1wPLFfVEvf2S+59A4AQnIA/0uAO9ndVbusNEfmFiGx1\nd+uUA9Hu7+/su54DFrpfLwReOIk6GdMuu9BjPIK7P/xqwF9E9rt3BwMxQDJQDwwHNhzx1lxgWgcf\nWwOEtdoe2E6Zw9ORuvvLf4nT0t6sqi4ROQhIq+8aDmxq53NeBDaJyCRgLPB2B3Uy5oRZC914isuB\nFpy+7Mnux1jgc5x+9cXAQyKS4r44OdM9rPFvwBwRuVpEAkQkXkQmuz9zPfA9EQkTkRHAjzupQyTQ\nDBQDASJyL05f+SHPAL8TkZHimCgi8QCqmofT//4C8MahLhxjupMFuvEU1wN/VdV9qrr/0AP4C3Ad\ncCewESc0y4A/AH6qug/nIuXt7v3rgUnuz3wYaASKcLpE/tZJHT4A3gd2AHtx/lXQukvmIeA1YDlQ\nCfwfENrq+HPAKVh3i+khYgtcGNM7ROQsnK6XIWp/8UwPsBa6Mb1ARAKBW4FnLMxNT7FAN6aHichY\noBzn4u0jfVwd48Wsy8UYY7yEtdCNMcZL9Nk49AEDBujQoUP76uuNMcYjrVu3rkRVE9o71meBPnTo\nULKysvrq640xxiOJyN6OjlmXizHGeAkLdGOM8RIW6MYY4yX61eRcTU1N5OXlUV9f39dV6VEhISGk\npqYSGBjY11UxxniRfhXoeXl5REZGMnToUESk8zd4IFWltLSUvLw80tPT+7o6xhgv0q+6XOrr64mP\nj/faMAcQEeLj473+XyHGmN7XrwId8OowP8QXztEY0/v6VZeLMcZ4q7KaRjbklfNtbgWzxyYyYVB0\nt3+HBXor5eXlvPTSS/zsZz87rvdddNFFvPTSS8TExPRQzYwxnsLlUkqqG9hTWsu3eeVsyKtgQ245\n+8pqARCBuIggC/SeVl5ezuOPP35UoDc3NxMQ0PEf1bJly3q6asaYfqSpxcWekhp2FFWTU1xN3sE6\n8svryDtYS2F5LVEt5cRINYUaR3RMPJMGR7NgehqTUmOYMCiKyJCeGeFmgd7KnXfeya5du5g8eTKB\ngYGEhIQQGxvLtm3b2LFjB5dffjm5ubnU19dz6623smjRIuC7aQyqq6uZN28es2bNYtWqVQwaNIh3\n3nmH0NDQTr7ZGB9TWwab34T4ETB4OgT2wt+RliYo3wcH99BcnkdjQAT1IYnUhSRRHRhPncufusYW\nGltcUFtGyMEdhJVvJ7xiJ5GVO5GGSipcwZQ2BVPcGEiVK4RqQgkFZgdWMNj/IEmUER1Ugr+2fPe9\n/glQPwzKhoGmQ80wSJsOMWndfor9NtDve3czWwoqu/Uzx6VE8dtLx3d4/IEHHmDTpk2sX7+elStX\ncvHFF7Np06bDwwsXL15MXFwcdXV1nHbaaVx55ZXEx8e3+YydO3fy8ssv8/TTT3P11VfzxhtvsHDh\nwva+zhjf09wIa5+BTx+A+gpnn38QpE6D9DMh/SwYlAEBQV36OFVlW84e9mdvQOsroKEKaajCr6mS\ngMYqAhvLiarLJ66xgPiWA/jjApzgC6DtCuHFGkWxxhIvFSRJ+eH9lRrGNh1MhUYRF9hAQkAVw8Pq\nCdM6glpq8EORqBSISoGoSe7nFAiNhYo8KMtxHrs/gw0vOx96ycOQ8aOT//M8Qr8N9P5g2rRpbcaK\n/+lPf+Ktt94CIDc3l507dx4V6Onp6Uye7KxBPHXqVPbs2dNr9TWm31KFHR/A8t9AaTYMPw/Ouxtq\nSmHPZ07YrXwAVv4XBIRCymRIngTJk53XA0aBnz8A9RUHyF7zPlXbVpJQtpaxuo+x7Xxlk/pTJeEU\n+SWxLXA0FRGzqQ4bTENkGq6oVGL8aolpKSW6qYTIpmLCGw4wsKEYV2gcBXGjaYofQ8uAMRCZQnKA\nP+PCg4gIPsnIbKqDg3sgvN3JEk9al2onInOBRwF/nCW0HjjieBrOArgx7jJ3qupJdSwfqyXdW8LD\nww+/XrlyJStWrCAzM5OwsDDOOeecdseSBwcHH37t7+9PXZ0t7m76GVWoL4fqYqgrc/aJH4g/+Pk5\nr/0CIDoVQrpw4U4VakqgthQCQyAwDALcz/4BULQFPvg15HwC8SNhwesw8nzn6iDAqAuc57qDsOdL\n2PMFFHwNXz8PTU8C0OIfSknEKJrqKklt3M0EoFaD2R12ChuHXEHCqOkER8YTGBZFUHgsgWHRBAaG\nEidCHLQb+H0iMBQSe642nQa6iPgDjwHnA3nAWhFZqqpbWhW7G3hNVZ8QkXHAMmBoD9S3R0VGRlJV\nVdXusYqKCmJjYwkLC2Pbtm2sXr26l2tnzHFyuaBwPexcDnlZUHPACfGaYnA1de0zIpOd1nHCGEgY\nBQNGQ0sDFG93HiU7oHibE8bt8QsAVwsaEs3Bs37HN4nfY0dBAzvXb2BfaS2B/n6EBwcQEezvfh5O\naNAo9scsYFdDBc0HtjO0MZtT/HYzvmkP4h/F1uRFxI+fzbiMsxkfYtenWutKC30akK2qOQAi8gpw\nGdA60BWIcr+OBgq6s5K9JT4+njPOOIMJEyYQGhpKUlLS4WNz587lySefZOzYsYwePZoZM2b0YU2N\n6UB9Bez6xAnxnR86IY5A0gSnXzfpFIhIgPBE55/9YbFOi9zlAm0BdYGrBVoaoXwvFLsDe/3foLG6\n7XeFxkHCGBpGXcr+oKEUuSKpr6ulqb6G5vpamhtraWmso6wxkMerz+LA8jBgAwBJUcEMiQ+nqcVF\n3sFaahqbqWloobqhmcZmF7FhgYxMimTcpOmMTJzNyKRI0hMjSIgMthvzjqHTNUVF5Cpgrqr+xL39\nfWC6qt7SqkwysByIBcKBOaq67lifm5GRoUcucLF161bGju03/zjqUb50ruYEHdwDQZEQFvdd98SR\nmhsgb63TB737c8hbA65mp6tkxBwYeaHzHB7f/vs7oarUN7moqmukpjSXlqJt7K9x8XVdEutLA9hW\nWElBRduuRxGICgkkJiyQmNBA4sKDGJ4QwcikCEYkRjIiMYLo0I6H7TW3uAjw73c3sfcbIrJOVTPa\nO9ZdF0WvBZ5V1QdFZCbwgohMUFXXERVZBCwCSEvr/iE7xni8lmbY9ndY/QTkurv1QmIgfjjEDXc/\nD3Naz7s/h9yvoLneaWUnT4KZt8CoC51RI/4d//Wub2ohc1cpq3NKKa9torqxmer6Zmoamqlu/ahv\nptnVutHnD/gT6H+Q4QkRTEuPY/TAKMYkRzI0PpzYsEAiQwLx9zvxVrSF+YnrSqDnA4Nbbae697X2\nY2AugKpmikgIMAA40LqQqj4FPAVOC/0E62yMZ1CFilzYtxr2ZUL1ASd0U6Y4ozciWo10qCt3LgKu\necp5T8wQOP9+pw+6dJczMmRfJmx87bv3JE1whr4NPROGnA6hx75TuaS6gY+3HWDFliI+31lCXVML\nQQF+xIYFuvuvncfg8LDDryNDAogMCXQ/O4+UmFCGDYggKMCCt7/pSqCvBUaKSDpOkF8DLDiizD5g\nNvCsiIwFQoDi7qyoMR6hZCfkrHTCd99qqHS3fYKjICIRtr2Hc8kJiB7sDMkLiYZNb0FTDQyZBXMf\ngNHzDg/Ta6P1sLfwAW0Oldc2srukhrKaRspqGjlY20hZTRMHaxrZeaCKb3LLUYWU6BCumprKnHFJ\nzBgWR3BAO99jPFKnga6qzSJyC/ABzr+3FqvqZhG5H8hS1aXA7cDTInIbzq/1Bu2sc94Yb6AK+zfC\n1ndh61LnAiJAZAoMmQlpMyFtBiSOcwK6oQoKv3WG5RV84zwqC2D892DGTU4L/lhaDXsrrW5gze4y\nvtpdxuqcUrbtP3qEVqC/EBceRHJ0KD+fPYo54xIZlxxlFxa9VJf60N1jypcdse/eVq+3AGd0b9WM\n6aeaG5wg3vaeE+IH9zh92EPOgIwfO+OqY4a0fyEzOBKGnuE8DlHt+KInzoXJgop6sg9Uk32gmp1F\nVazbe5CdB5xRJ6GB/mQMjeWSicmMS4kiPjyYuPAgYsODCA/yt/D2IXanqDGdqSx0Ro/kuh+F651h\nfX6BMOxsmHUbjL64bZ/4cVCgoraRgvJ69lfWUVBeT2GF87yruJpdB6qpafxubpCYsEAmpsZw+ZRB\nzBgWzymDoq0/2wAW6G2c6PS5AI888giLFi0iLCys88Km99WUOK3pqv3OBcRjTQjV3Ah7v4Bty2Dn\nB86ETgD+wc4Fzek3weBpMHSWM19HF7hcSn55HXtLa9lTWsO+slr2lDjP+8pqqW0V2AD+fkJSZDDD\nEiL4p4zBDE+MYGRiBCMSI4gPD7JWt2mXBXorHU2f2xWPPPIICxcutEDvT2rLnCGAm950xmlrCyCA\nOuGcNt2ZDCr9HGcoYM4nTjdK9gpoqHTmFBl+Hkz/FyfAB07s8qRRRZX1rM8tZ0Nu+eFFDaoamg8f\nDwrwIy0ujKHxYcwcHs+gmFCSo0NJjgkhJTqUhMjgkxr6Z3yTBXorrafPPf/880lMTOS1116joaGB\nK664gvvuu4+amhquvvpq8vLyaGlp4Z577qGoqIiCggLOPfdcBgwYwCeffNLXp+K7mhudlvi3r8Ku\nj52bbGLTYdbPnQuPsUNg7yon4HM+hY//E/jP794fngDjLoMxF8Owc7o8rWtVfROf7ihm+eYi1uwu\nY3+lc7NNgJ8wJjmS+ZNTGJ8STfqAcIbEhzEwKgQ/C2zTzfpvoP/jTmf0QHcaeArMe6DDw62nz12+\nfDlLlixhzZo1qCrz58/ns88+o7i4mJSUFN577z3AmeMlOjqahx56iE8++YQBAwZ0+PnmBFXkObeq\nH6t1XFkAWX+Fdc86t7tHD4YZP4MJ33PGfLfuohh1ofMApytm92fO9KaHpm7161p/9IGqelZsOcDy\nLftZlV1KY4uL+PAgZo0cwOTBMUwaHMO45ChCAm1YoOkd/TfQ+9jy5ctZvnw5U6ZMAaC6upqdO3dy\n5plncvvtt/OrX/2KSy65hDPPPLOPa+rFSrLhg7uceUn8gyF5ohO4qRkwaCrEDnVa22uecoYNqssJ\n6mk/hWHndS2Ywwc4od8FFXVNrNt7aJhgGd/mOeO60+LCuP70IVwwfiCnpsVaV4npM/030I/Rku4N\nqspdd93FjTfeeNSxr7/+mmXLlnH33Xcze/Zs7r333nY+wZywhir47L8h83FnGtaz73Ruuslb57TA\nv3rCKRcY7uwPiYGZP3OGDMalH/Oju0rVuYi5Ma+Cr3aXsWZ3GVv3V6LqjO2emBrDbXNGccH4JEYn\nRdpFStMv9N9A7wOtp8+98MILueeee7juuuuIiIggPz+fwMBAmpubiYuLY+HChcTExPDMM8+0ea91\nuZwEl8vp+17xW6gugskLYfa9EPndrJe0NMOBLZCf5XTJJU+GU/4Jgk78YnSLS9lXVsum/Ao2FVSw\nOb+STQUVlNc6U8yGBPoxdUgsP589imnpcUxJi7FuFNMvWaC30nr63Hnz5rFgwQJmzpwJQEREBC++\n+CLZ2dnccccd+Pn5ERgYyBNPOK3FRYsWMXfuXFJSUuyi6InYuwqW3+ME9aAMuOZlSJ16dDn/AKfr\nJXnicX9FQ3MLO/ZXO2O7i6vJKa5xnktqaGx25pEL8vdj9MBI5k0YyPiUaCYMimZccpSN8zYeodPp\nc3uKTZ/rxee650v3UmIhcOoPnHlJ/DuYLnVvplN296cQkQRz/gMmXtPlC5PH4nIpWwor+TK7hC+y\nS1i7p4z6Jie4/f2EtLgwhieEMzwhguEJEYwfFMXIxEgLb9Ov9cb0ucY4swJ+eK8z9jsyxRlZ8tr3\nnREqkxc44R4/3CnbOsjDE+HC/wdTf3hSXSeqSk5JDV/llPHlrhJWZZdw0N1tMiopgmunpTFtaBwj\nkyJIiwu34DZexwLdnLzaMvj0D85q7gEhzuK/M26GgGDnJp11z8KqP8OXjzhDAxF3kCfABb93poA9\ngSBXVXYV1/DV7lJW5zgTVBVXNQDOijjnjUli1sh4zhg+gMSokO49Z2P6oX4X6Krq9SMGPH4iypZm\nqNjnjN3O/wYy/+yMTDn1B3Dub5xpYg85NOa7sgC++Zsz53dz/QkHeYtLWbunjH9sLOT9zfspqvwu\nwE8fHs+MYfFMT48jfUC41/+OjDlSvwr0kJAQSktLiY+P99q/jKpKaWkpISEe1GIs+AY2vAqlO50Q\nL9/n3IF5yIg5cP7vIGlcx58RlQJn3wFn/eKYMwu2p7nFxZrdZSzbVMj7m4ooqW4gOMCPc0YncO7o\nRGYMi2dIfJjX/maM6ap+Feipqank5eVRXOzda2OEhISQmpra19U4NlXY9RF8+ahzJ2VAqLPqe/Ik\nGH+FM/dJ3DBnWbTWwwo708XQVVU25FXw1td5/P3bQkprGgkN9Oe8MYnMO2Ug545OJDy4X/18jelz\n/epvRGBgIOnp3XNjiDlBLU3OZFar/gRFmyAy2VkKbeoNzso6PSy3rJa3vsnn7W/yySmpISjAjzlj\nE7l0YgrnjE4kNMjGfxvTkX4V6KYPqcLGJbDiP6AyDxLGwGWPOzftdHGGwRPR4lI2F1SwalcpH20t\nYu2egwBMT4/jxrOHMe+UZKJCOl4h3hjzHQt044xS+fttsOVtZ46USx6CEed3y1jwI7lcyvaiKlbt\nKiVzVylf7S6lqt7pjx8zMJI7LhzNZZNTSI21aYiNOV4W6L5ux3JYeosT6rN/C2fc2v7ixCepoLyO\nJevyeH1dLrlldQAMiQ/jkonJzBw+gBnD4kiM9KALxcb0QxbovqqhGpb/xhkjnjgeFr7hTC/cnV/R\n3MKKLQd4NSuXz3cWowqnD4/nX88dyRkjBzAopmtzjRtjusYC3RftzYS3b4KDe50W+bm/cW4C6gaH\nRqe8/U0+76zP52BtE8nRIfzruSO4aupg0uKtK8WYnmKB7kvqK5yLnlmLnVXpf7jMWV+zG2QfqOKd\n9QUs3VDA3tJagvz9mDMukaszBnPmyASbI9yYXmCB7iu2vgvL7nCmpZ15C5xzFwRHnNRH1je18OLq\nvbz5dT5bCivxEzh9+ABuPncEF44fSHSojU4xpjdZoHu7ygInyLf93ekjv+YlGHTqSX2kqrJs437+\n37Kt5JfXMXlwDL+9dBwXT0y2C5vG9KEuBbqIzAUeBfyBZ1T1gSOOPwyc694MAxJVNaY7K2pOwDcv\nwvt3QUsjzLkPZt7c8TS2XbS5oIL73t3Cmt1ljE2O4sGrJzFjWHw3VdgYczI6DXQR8QceA84H8oC1\nIrJUVbccKqOqt7Uq/6/AlB6oqzke296Dd26GoWfCpY9+N23tCSqtbuDBD3fwypp9RIcG8vsrJnDN\naWnWN25MP9KVFvo0IFtVcwBE5BXgMmBLB+WvBX7bPdUzJ6QkG966CVKmwHVLIPDEu0Eq6pp49ss9\nPPNFDnWNLdxwejq3zh5JdJj1jxvT33Ql0AcBua2284Dp7RUUkSFAOvBxB8cXAYsA0tLSjquiposa\na+DVheAXAFc/f8JhfrCmkcVf7ubZL/dQ1dDMnLFJ3DlvNCMSI7u5wsaY7tLdF0WvAZaoakt7B1X1\nKeApcJag6+bvNqqw9N+geBt8/02IOf7/aZZWN/D057t5IXMPNY0tzJswkFvOG8H4lJ6fmMsYc3K6\nEuj5wOBW26nufe25Brj5ZCtlTtBXT8KmJXDePTD8vON666b8Cl5es483v86nvrmFSyamcMu5Ixg9\n0FrkxniKrgT6WmCkiKTjBPk1wIIjC4nIGCAWyOzWGhpH0RbY8Q9ImwmDpx8938reVbD8bhh9Ecz6\n9y59ZFV9E++sL+CVtfvYlF9JcIAfl05K4aazhzMi8eTGqBtjel+nga6qzSJyC/ABzrDFxaq6WUTu\nB7JUdam76DXAK+rx66v1M+X74JP/gg0vA+4/2ogkGHMxjJ0PQ2dBbSm8foPTxXLFk53Okrgpv4Ln\nM/fw7oZC6ppaGJscxf2XjeeyyYPsZiBjPJj0Vf5mZGRoVlZWn3y3R6gtg88fhDVPAQLTb4RpP4Xc\nNbB1Kez8EJpqITQWQmKcO0B/sgKSxnf4kdv3V/Hwhzt4f/N+woL8uWxyCteclsbE1Ghbvs0YDyEi\n61Q1o71jdqdof9NYC6sfgy//BI3VMHmBc5t+tHvJupg0OOUqp9yuj5xb+nd/Bpc91mGY7y6p4ZEV\nO1i6oYCIoAB+PmckP5qVbgtHGONlLND7k7qD8OKVkL8ORl8Ms++BxLHtlw0Kg7GXOo8O5JbV8ueP\nd/LG1/kE+ftx09nDWXTmMGLDe24FImNM37FA7y9qSuCFy6F4O/zzi8cM6s4UVdbzl4+zeWXtPkSE\n62cO5V/OGU5CZPdMkWuM6Z8s0PuDqv3w3Hwo3wvXvgwj5pzQx5RWN/Dkp7t4PnMvLS7ln08bzC3n\njSA52haSMMYXWKD3tfJceH4+VB9wVg0aOuu4P6KitomnP89h8Ze7qW9q4XunpnLr7JEMjrPFJIzx\nJRbofaksx2mZ11fC99+Gwacd90es2FLE7a9voKKuiUsmJnPb+aMYnmBjyI3xRRbofaV4uxPmLY1w\n/VJImXxcb29xKY+u2MGfPs5mwqAoXr5yBuNSonqossYYT2CB3hdKsuHZS5zXP1zW8UiWDpTXNnLr\nK+v5dEcx/zQ1ld9dPoGQQP/O32iM8WoW6L2tbDc8dymgcMMySBh1XG/fXFDBTS+uY39FPb+/YgIL\npqXZTUHGGMACvXdV5DkXQJvr4Pq/H3eYv7Euj1+/tZHYsCBeu3EmU9Jie6iixhhPZIHeWw4NTawr\nd/rMB07o8lt3FlXxh/e3sWLrAWYMi+MvC05lQISNKTfGtGWB3htqSuD5y5xQ//5bzkpCXVBUWc/D\nH+7gtaxcwoMC+NXcMfz0zHQC/I89+ZYxxjdZoPe0uoPOHaAH9zjLwaW1u9hTG1X1Tfzvpzk880UO\nLS7lhtPTueW8EcTZLfvGmGOwQO9JdeXO3CzF2507QNPP7PQtf/+2gHvf2UxZTSOXTkrhjgtGkxZv\nNwgZYzpngd5TakqdlvmBrc7anp3czq+qPLxiJ3/6aCeTB8fw7A9PY2JqTC9V1hjjDSzQe0L1AafP\nvCwHrn0FRh47zOubWvjF6xv4+7eFXDU1ld9fMYHgABtXbow5Phbo3a2ywBnNUpkPC16DYWcfs/iB\nqnp++vw6vs0r5855Y7jxrGE2rtwYc0Is0LvTwb3OOPOaUmc0S9qMYxbfUlDJT55by8HaJp5cOJUL\nxw/spYoaY7yRBXp3Kd3ltMwbq+AH70Dq1GMW/2hrEf/68jdEhwby+k0zmTAoupcqaozxVhbo3aEi\nH/56EbianDtAkyces/jSDQXc9up6xqdE8cwPMkiMCumlihpjvJkF+slyueDtf4GGKvcizeOOWXzJ\nujx+uWQDGUPjWHzDaUQE238CY0z3sDQ5WWuegt2fwiWPdBrmL321j1+/tZFZIwbw9A8yCA2ykSzG\nmO5jgX4yirfDit/CyAth6g3HLPrXL3dz37tbOHd0Ak8snGrT3Rpjul2XJgURkbkisl1EskXkzg7K\nXC0iW0Rks4i81L3V7IdamuDNRRAYBvP/DMcYavjEyl3c9+4WLhyfxP9+P8PC3BjTIzptoYuIP/AY\ncD6QB6wVkaWquqVVmZHAXcAZqnpQRBJ7qsL9xmf/DYXrnbtAI5M6LPboip08vGIHl05K4aGrJxFo\nE2sZY3pIV9JlGpCtqjmq2gi8Alx2RJmfAo+p6kEAVT3QvdXsZ/Ky4LP/gYnXwLgj/yi+88TKXTy8\nYgdXnprKI/882cLcGNOjupIwg4DcVtt57n2tjQJGiciXIrJaROa290EiskhEskQkq7i4+MRq3Nca\na5yulshkuOiPHRZ7PnMPf3h/G/MnpfDHqybi72d3fxpjelZ3NRkDgJHAOcC1wNMictTMUqr6lKpm\nqGpGQkJCN311L/vwXijbBZc/DiHt3wy0ZF0e976zmTljk3jw6kkW5saYXtGVQM8HBrfaTnXvay0P\nWKqqTaq6G9iBE/DeZeu7sPYZmPGzDudo+cfGQn65ZANnjIjnLwumWDeLMabXdCVt1gIjRSRdRIKA\na4ClR5R5G6d1jogMwOmCyenGeva9nJWw5EcwaCrMvrfdIp9sP8C/vfINU9JiefoHNprFGNO7Og10\nVW0GbgE+ALYCr6nqZhG5X0Tmu4t9AJSKyBbgE+AOVS3tqUr3utw18PICiB/hrDoUGHpUkdU5pdz0\nwjpGJUWy+IbTCAuyIf7GmN4lqtonX5yRkaFZWVl98t3HpfBbeO4SCIuHH77f7hDFL7NLuPGFdQyM\nDuHVRTOItwWcjTE9RETWqaWnuXwAABIcSURBVGpGe8esg/dYSnbCC1dAUKQzg2I7Yf7a2lyuX7yG\nlJgQXvzxdAtzY0yfsX6BjpTvc1YdEnHCPCatzWGXS/mf5dt5fOUuzhw5gMeuO5WokMA+qqwxxlig\nt6+y0Anzxmq44T0YMKLN4fqmFm5/fQPvfVvItdPSuP+y8TaaxRjT5yzQW6stg8y/wFf/C6pOy3zg\nKW2KlFY38NPns/h6Xzm/vmgMPz3TlowzxvQPFujgDvLHnCBvrIbxl8M5d0HC6DbF9pXWsvD/vqKo\nsp4nrjuVeack91GFjTHmaL4d6O0F+Vm/bHde8/qmFm58cR0VdU28smgGU9Ji+6DCxhjTMd8NdJcL\nnrsUijbB+Cs6DPJDfvvOZrYWVvLXH55mYW6M6Zd8N9CzVzhhftljMGXhMYsuWZfHq1m53HzucM4d\n7f0zAxtjPJPvDs3I/AtEpsApVx+z2Lb9ldz99kZmDovntjmjeqlyxhhz/Hwz0PdvctYBnb4IAoI6\nLFZV38TPXvyayJBAHr12MgE2NNEY04/5ZkKtftxZOu4Y64CqKne+uZE9pTX8+dopJEaG9F79jDHm\nBPheoFcVwcbXYfJ1ENrxxc3nM/fy3reF3HHhGGYMi+/FChpjzInxvUBf+4yzwPOMf+mwyPrccv7z\nvS3MHpPIjWcN68XKGWPMifOtQG+qg6z/g9HzIH54u0VcLuU3b20kISKYB6+ehJ+tNmSM8RC+Fejf\nvgq1pTDz5g6LvL95P5sLKrn9gtHEhHV8wdQYY/ob3wl0Vch8HAZOhCFntFukxaU89OEORiRGcPmU\nI9fBNsaY/s13Aj37IyjZDjNvcabEbcfb3+STfaCa288fZQs7G2M8ju8EeuZfIDLZuc2/HY3NLh75\naAcTBkUxd8LAXq6cMcacPN8I9KItkPMJTPtphzcSvZqVS25ZHbdfMNqmwzXGeCTfCPTVj7lvJPph\nu4frm1r4y8c7yRgSyzmjEnq5csYY0z28P9DrDsK3r8OkayEsrt0iL2TupaiygV9caK1zY4zn8v5A\n3/outDTAqd9v93B1QzNPfOqsC2p3hBpjPJn3B/rGJRA3DJInt3t48Re7Katp5BcXjG73uDHGeArv\nDvSqItjzOUy4qt2hiuW1jTz9WQ4XjEti0uCYPqigMcZ0ny4FuojMFZHtIpItIne2c/wGESkWkfXu\nx0+6v6onYMvboC6YcGW7h5/8NIfqxmZut9a5McYLdLpikYj4A48B5wN5wFoRWaqqW44o+qqq3tID\ndTxxG5dA0gRIHHPUoar6Jl5cvZdLJqYwemBkH1TOGGO6V1da6NOAbFXNUdVG4BXgsp6tVjc4uBfy\n1nTYOl+yLo/qhmZ+Miu9lytmjDE9oyuBPgjIbbWd5953pCtF5FsRWSIig9v7IBFZJCJZIpJVXFx8\nAtU9DpvecJ7bCXSXS3lu1R5OTYuxvnNjjNforoui7wJDVXUi8CHwXHuFVPUpVc1Q1YyEhB6+gWfT\nm5A6DWKHHHXo0x3F7Cmt5YYzrHVujPEeXQn0fKB1izvVve8wVS1V1Qb35jPA1O6p3gkq3g5FGzvs\nbln85W6SooKZZ3O2GGO8SFcCfS0wUkTSRSQIuAZY2rqAiCS32pwPbO2+Kp6AjUtA/NqdiCv7QBWf\n7yxh4fQhBNqiz8YYL9LpKBdVbRaRW4APAH9gsapuFpH7gSxVXQr8m4jMB5qBMuCGHqxzZxWGTUtg\n6JkQmXTU4edW7SUowI8F09P6oHLGGNNzOg10AFVdBiw7Yt+9rV7fBdzVvVU7QYXroSwHzvj5UYcq\n6pp44+s85k9KIT4iuA8qZ4wxPcf7+hw2LgG/QBg3/6hDr2flUtvYwg2nD+39ehljTA/zrkB3uWDz\nWzBiDoTGtjnU4lKey9zDaUNjmTAoum/qZ4wxPci7An1fJlTmwylXHXXo420HyC2r44c2VNEY46W8\nK9A3vQEBoTBq7lGH/vrlbpKjQ7hg3NEXSo0xxht4T6C3NDmTcY2eB8ERbQ5t31/Fql2lfH/mEAJs\nqKIxxkt5T7rtXQW1pTDhe0cdenbVHoID/Lj2NBuqaIzxXl4U6F8CAulntdld29jMW9/kcfnkQcSG\nt79AtDHGeAMvCvRVMPAUCGk7gmXtnoPUN7m4aGJyB280xhjv4B2B3twIeVkw5PSjDq3aVUKgv3Da\n0Nh23miMMd7DOwK9cAM010HazKMOZe4qZcrgWMKCunRTrDHGeCzvCPR9q5znI1roFbVNbMqvYObw\n+D6olDHG9C7vCPS9mRA3HCIS2+z+ancpLoXTLdCNMT7A8wPd5XLuEB1ydHfLql2lhAT6MTnNViUy\nxng/zw/04m1QXw5p7V8QPW1oHMEB/n1QMWOM6V2eH+iH+8/bttCLqxrYUVTN6cMH9EGljDGm93l+\noO/NhMhkiG076VZmTilg/efGGN/h2YGu6txQlDYTRNocytxVQmRIAONTovqocsYY07s8O9DL90JV\nQbs3FH2ZXcr09HibjMsY4zM8O+32ZjrPR9xQlFtWy76yWs4YYd0txhjf4dmBvm+VM3dL4rg2u7/r\nP7cLosYY3+HZgb43EwbPAL+2p5G5q5T48CBGJUV08EZjjPE+nhvo1cVQuvOo4YqqyqpdJcwcHo8c\ncaHUGGO8mecG+r5D/edtL4jmlNRQVNlg3S3GGJ/TpUAXkbkisl1EskXkzmOUu1JEVEQyuq+KHdiX\nCQEhkDKlze5V2SUAdkHUGONzOg10EfEHHgPmAeOAa0VkXDvlIoFbga+6u5Lt2rsKUk+DgLarEK3a\nVcqgmFDS4sJ6pRrGGNNfdKWFPg3IVtUcVW0EXgEua6fc74A/APXdWL/2NVTB/m+PGq7ocimZOaXW\nf26M8UldCfRBQG6r7Tz3vsNE5FRgsKq+d6wPEpFFIpIlIlnFxcXHXdnDcteAuo66ILp1fyXltU12\nu78xxied9EVREfEDHgJu76ysqj6lqhmqmpGQkHDiX7ovE8QfUqe12Z25y8afG2N8V1cCPR8Y3Go7\n1b3vkEhgArBSRPYAM4ClPXphdG8mJE+E4LbjzFftKmVYQjgDo0N67KuNMaa/6kqgrwVGiki6iAQB\n1wBLDx1U1QpVHaCqQ1V1KLAamK+qWT1S4+YGyFt71HDFphYXX+WUWneLMcZndRroqtoM3AJ8AGwF\nXlPVzSJyv4jM7+kKHqXgG2hpOKr/fHNBJTWNLcwcZt0txhjfFNCVQqq6DFh2xL57Oyh7zslX6xj2\nuhe0OGKEy76yWgBG2u3+xhgf1aVA71cmXg1xwyC8bUu8sLwOgGTrPzfG+CjPC/ToVOdxhMKKeiKD\nA4gMCeyDShljTN/z3LlcjlBQXkdyjLXOjTG+y2sCvbCinoHRoX1dDWOM6TNeFegp1n9ujPFhXhHo\nDc0tlFQ3kGwtdGOMD/OKQC+qaACwPnRjjE/zikAvqHCGLKZYC90Y48O8ItD3Vzgz9tocLsYYX+YV\ngX64hW5dLsYYH+YVgV5YXk90aCBhQZ53n5QxxnQX7wj0ijq75d8Y4/O8ItALyutJibELosYY3+YV\ngb6/st4uiBpjfJ7HB3p9UwtlNY12l6gxxud5fKAXuocs2l2ixhhf5/mBfmgedBuyaIzxcR4f6AXu\nFrrdJWqM8XUeH+j73TcV2UVRY4yv8/hAL6ioJy48iJBA/76uijHG9CmPD/TCcrupyBhjwBsCvaLe\nRrgYYwxeEug2KZcxxnQx0EVkrohsF5FsEbmzneM3ichGEVkvIl+IyLjur+rRahubqahrsguixhhD\nFwJdRPyBx4B5wDjg2nYC+yVVPUVVJwN/BB7q9pq2o6DchiwaY8whXWmhTwOyVTVHVRuBV4DLWhdQ\n1cpWm+GAdl8VO1boHrJoF0WNMQa6MoH4ICC31XYeMP3IQiJyM/DvQBBwXrfUrhOFh1roNtOiMcZ0\n30VRVX1MVYcDvwLubq+MiCwSkSwRySouLj7p7zw0j0tSlLXQjTGmK4GeDwxutZ3q3teRV4DL2zug\nqk+paoaqZiQkJHS9lh0orKhjQEQwQQEeP1jHGGNOWleScC0wUkTSRSQIuAZY2rqAiIxstXkxsLP7\nqtixAhuyaIwxh3Xah66qzSJyC/AB4A8sVtXNInI/kKWqS4FbRGQO0AQcBK7vyUofUlhex7CE8N74\nKmOM6fe6tKqyqi4Dlh2x795Wr2/t5np1SWFFPWeMGNAXX22MMf2Ox3Y+V9U3Ud3QbEMWjTHGzWMD\n/fBKRTZk0RhjAA8O9AL3SkW2lqgxxjg8NtCthW6MMW15dKD7CSRGBvd1VYwxpl/w3EAvryMhMphA\nf489BWOM6VYem4a2sIUxxrTlsYFeUFFnd4kaY0wrHhnoqkphubXQjTGmNY8M9Mq6ZuqaWuymImOM\nacUjA73g8MIW1kI3xphDPDLQD69UZH3oxhhzmEcGuq0laowxR/PIQC+sqCPAT0iwm4qMMeYwDw30\nepKiQvD3k76uijHG9BueGejl9Qy0ES7GGNOGZwZ6RZ0NWTTGmCN4XKCrKoUV9aTYLIvGGNOGxwV6\nWU0jDc0ua6EbY8wRPC7QD8+DbkMWjTGmDQ8OdGuhG2NMax4Y6HaXqDHGtMfjAn1gVAjnj0tiQLjd\nVGSMMa0F9HUFjtcF4wdywfiBfV0NY4zpd7rUQheRuSKyXUSyReTOdo7/u4hsEZFvReQjERnS/VU1\nxhhzLJ0Guoj4A48B84BxwLUiMu6IYt8AGao6EVgC/LG7K2qMMebYutJCnwZkq2qOqjYCrwCXtS6g\nqp+oaq17czWQ2r3VNMYY05muBPogILfVdp57X0d+DPyjvQMiskhEskQkq7i4uOu1NMYY06luHeUi\nIguBDOC/2zuuqk+paoaqZiQkJHTnVxtjjM/ryiiXfGBwq+1U9742RGQO8BvgbFVt6J7qGWOM6aqu\ntNDXAiNFJF1EgoBrgKWtC4jIFOB/gfmqeqD7q2mMMaYznQa6qjYDtwAfAFuB11R1s4jcLyLz3cX+\nG4gAXheR9SKytIOPM8YY00NEVfvmi0WKgb0n+PYBQEk3VsdT+Op5g++eu523b+nKeQ9R1XYvQvZZ\noJ8MEclS1Yy+rkdv89XzBt89dztv33Ky5+1xc7kYY4xpnwW6McZ4CU8N9Kf6ugJ9xFfPG3z33O28\nfctJnbdH9qEbY4w5mqe20I0xxhzBAt0YY7yExwV6Z3OzewsRWSwiB0RkU6t9cSLyoYjsdD/H9mUd\ne4KIDBaRT9zz628WkVvd+7363EUkRETWiMgG93nf596fLiJfuX/vr7rv1vY6IuIvIt+IyN/d215/\n3iKyR0Q2um/GzHLvO6nfuUcFehfnZvcWzwJzj9h3J/CRqo4EPnJve5tm4HZVHQfMAG52/zf29nNv\nAM5T1UnAZGCuiMwA/gA8rKojgIM4s5l6o1tx7kQ/xFfO+1xVndxq7PlJ/c49KtDpwtzs3kJVPwPK\njth9GfCc+/VzwOW9WqleoKqFqvq1+3UVzl/yQXj5uauj2r0Z6H4ocB7OojHghecNICKpwMXAM+5t\nwQfOuwMn9Tv3tEA/3rnZvU2Sqha6X+8HkvqyMj1NRIYCU4Cv8IFzd3c7rAcOAB8Cu4By93xK4L2/\n90eAXwIu93Y8vnHeCiwXkXUissi976R+5x63SLRxqKqKiNeOORWRCOAN4OeqWuk02hzeeu6q2gJM\nFpEY4C1gTB9XqceJyCXAAVVdJyLn9HV9etksVc0XkUTgQxHZ1vrgifzOPa2F3qW52b1YkYgkA7if\nvXKqYhEJxAnzv6nqm+7dPnHuAKpaDnwCzARiRORQw8sbf+9nAPNFZA9OF+p5wKN4/3mjqvnu5wM4\n/wOfxkn+zj0t0Dudm93LLQWud7++HninD+vSI9z9p/8HbFXVh1od8upzF5EEd8scEQkFzse5fvAJ\ncJW7mNedt6repaqpqjoU5+/zx6p6HV5+3iISLiKRh14DFwCbOMnfucfdKSoiF+H0ufkDi1X1931c\npR4hIi8D5+BMp1kE/BZ4G3gNSMOZevhqVT3ywqlHE5FZwOfARr7rU/01Tj+61567iEzEuQjmj9PQ\nek1V7xeRYTgt1zjgG2Cht64I5u5y+YWqXuLt5+0+v7fcmwHAS6r6exGJ5yR+5x4X6MYYY9rnaV0u\nxhhjOmCBbowxXsIC3RhjvIQFujHGeAkLdGOM8RIW6MYY4yUs0I0xxkv8f81JEkBN8BWKAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8hIa6Eop5SX+P2zxG/yCd4CIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P0Wm_ye2JkH",
        "colab_type": "code",
        "outputId": "2a88010d-8166-4075-e66c-3dbb220465aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.15.0\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import metrics, callbacks\n",
        "\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "\n",
        "\n",
        "# setting\n",
        "base_name = 'cifar_cnn'\n",
        "epoch = 200\n",
        "learning_rate = 0.0001\n",
        "activation1 = 'relu'\n",
        "activation2 = 'softmax'\n",
        "optimizer = keras.optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
        "# optimizer = keras.optimizers.RMSprop(lr=learning_rate, decay=1e-6)\n",
        "optimizer_name = 'Adam'\n",
        "dropout = 0.40\n",
        "\n",
        "logging.basicConfig(filename='/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}.log'.format(\n",
        "                                base_name, epoch, learning_rate, activation1, optimizer_name, dropout),\n",
        "                    level=logging.DEBUG,\n",
        "                    format='[%(asctime)s] %(name)s %(levelname)s \\n%(message)s'\n",
        "                    )\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "logger.info(\"-------------------- Learning Settings --------------------\")\n",
        "logger.info('epoch = {}'.format(epoch))\n",
        "logger.info('learning_rate = {}'.format(learning_rate))\n",
        "logger.info('activation_functions = {}, {}'.format(activation1, activation2))\n",
        "logger.info('optimizer = {}'.format(optimizer_name))\n",
        "logger.info('dropout = {}'.format(dropout))\n",
        "logger.info(\"-------------------- Start training! --------------------\")\n",
        "\n",
        "# 데이터 변수 선언\n",
        "num_classes = 10\n",
        "im_rows = 32\n",
        "im_cols = 32\n",
        "in_shape = (im_rows, im_cols, 3)\n",
        "im_size = im_rows * im_cols * 3\n",
        "\n",
        "# (1) 데이터 읽어 들이기 -----------------------------------\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "logger.info('-------------------- cifar10.load_data() --------------------')\n",
        "\n",
        "# (2) 데이터가공 ------------------------------------------\n",
        "# 3차원 변환 및 정규화\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "logger.info('-------------------- Reshaping. --------------------')\n",
        "\n",
        "# 레이블 데이터를 One-hot 형식으로 변환\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "logger.info('-------------------- One-hot Encoding. --------------------')\n",
        "\n",
        "\n",
        "# CNN 모델 정의하기\n",
        "model = Sequential()\n",
        "\n",
        "# convolution layers - 특징 맵 추출\n",
        "# polling layers - 특징 맵 축소 최대폴링/평균폴링\n",
        "# fully connected layers - 각 레이어 결합. 2차원 특징맵을 1차원으로 전개\n",
        "# activation function - 특징 강조\n",
        "# output layer - 출력 레이어\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=in_shape))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation(activation1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())    # 3차원 -> 1차원\n",
        "model.add(Dense(512))   # Dense가 1차원밖에 못 받음\n",
        "model.add(Activation(activation1))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(activation2))\n",
        "logger.info('-------------------- Define CNN model --------------------')\n",
        "# model.summary()\n",
        "logger.info(model.summary())\n",
        "\n",
        "# 모델 생성\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', metrics.categorical_accuracy]\n",
        ")\n",
        "logger.info('-------------------- model.compile() --------------------')\n",
        "\n",
        "# 학습 실행하기\n",
        "# 전체 데이터 반복 횟수 epochs => 50\n",
        "# 전체 데이터 1회 반복 시 학습 데이터 크기 32\n",
        "# validation_data => 각 epoch마다 검증 데이터 정확도 출력\n",
        "# validation_split => 데이터셋 비율\n",
        "logger.info(\"-------------------- Start model.fit() --------------------\")\n",
        "\n",
        "hist = model.fit(X_train, y_train,\n",
        "                 batch_size=32,\n",
        "                 epochs=epoch,\n",
        "                 verbose=1,\n",
        "                 validation_data=(X_test, y_test)\n",
        "                 )\n",
        "\n",
        "# 모델 평가하기\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "logger.info('Accuracy: {} / loss: {}'.format(score[1], score[0]))\n",
        "print('정답률=', score[1], ' / loss=', score[0])\n",
        "\n",
        "# 학습 상태를 그래프로 그리기\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "try:\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'accuracy', 'png'))\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'accuracy', 'svg'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "try:\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'loss', 'png'))\n",
        "    plt.savefig('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, 'loss', 'svg'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    logger.error(e)\n",
        "\n",
        "try:\n",
        "    model.save_weights('/content/gdrive/My Drive/cifar10/{}_epoch{}_lr{}_func{}_opt{}_dropout{}_acc{}.{}'.format(\n",
        "            base_name, epoch, learning_rate, activation1, optimizer_name, dropout, score[1], 'h5'))\n",
        "except Exception as e:\n",
        "    logger.error(e)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 556,586\n",
            "Trainable params: 555,690\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 26s 519us/step - loss: 2.1785 - acc: 0.2792 - categorical_accuracy: 0.2792 - val_loss: 1.5672 - val_acc: 0.4428 - val_categorical_accuracy: 0.4428\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 1.5992 - acc: 0.4153 - categorical_accuracy: 0.4153 - val_loss: 1.3486 - val_acc: 0.5129 - val_categorical_accuracy: 0.5129\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 22s 450us/step - loss: 1.4254 - acc: 0.4864 - categorical_accuracy: 0.4864 - val_loss: 1.2130 - val_acc: 0.5619 - val_categorical_accuracy: 0.5619\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 1.2920 - acc: 0.5370 - categorical_accuracy: 0.5370 - val_loss: 1.1176 - val_acc: 0.5992 - val_categorical_accuracy: 0.5992\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 1.1868 - acc: 0.5784 - categorical_accuracy: 0.5784 - val_loss: 1.1398 - val_acc: 0.6059 - val_categorical_accuracy: 0.6059\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 1.1060 - acc: 0.6089 - categorical_accuracy: 0.6089 - val_loss: 0.9551 - val_acc: 0.6609 - val_categorical_accuracy: 0.6609\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 1.0353 - acc: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 0.8854 - val_acc: 0.6845 - val_categorical_accuracy: 0.6845\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.9752 - acc: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.8545 - val_acc: 0.6993 - val_categorical_accuracy: 0.6993\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.9258 - acc: 0.6726 - categorical_accuracy: 0.6726 - val_loss: 0.8292 - val_acc: 0.7076 - val_categorical_accuracy: 0.7076\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.8798 - acc: 0.6915 - categorical_accuracy: 0.6915 - val_loss: 0.7645 - val_acc: 0.7289 - val_categorical_accuracy: 0.7289\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.8417 - acc: 0.7031 - categorical_accuracy: 0.7031 - val_loss: 0.7142 - val_acc: 0.7480 - val_categorical_accuracy: 0.7480\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.8014 - acc: 0.7217 - categorical_accuracy: 0.7217 - val_loss: 0.7057 - val_acc: 0.7476 - val_categorical_accuracy: 0.7476\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.7734 - acc: 0.7268 - categorical_accuracy: 0.7268 - val_loss: 0.6605 - val_acc: 0.7650 - val_categorical_accuracy: 0.7650\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.7507 - acc: 0.7357 - categorical_accuracy: 0.7357 - val_loss: 0.6907 - val_acc: 0.7591 - val_categorical_accuracy: 0.7591\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.7235 - acc: 0.7449 - categorical_accuracy: 0.7449 - val_loss: 0.6492 - val_acc: 0.7721 - val_categorical_accuracy: 0.7721\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.6958 - acc: 0.7572 - categorical_accuracy: 0.7572 - val_loss: 0.6228 - val_acc: 0.7848 - val_categorical_accuracy: 0.7848\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.6788 - acc: 0.7621 - categorical_accuracy: 0.7621 - val_loss: 0.6204 - val_acc: 0.7838 - val_categorical_accuracy: 0.7838\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.6497 - acc: 0.7720 - categorical_accuracy: 0.7720 - val_loss: 0.6351 - val_acc: 0.7812 - val_categorical_accuracy: 0.7812\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.6396 - acc: 0.7772 - categorical_accuracy: 0.7772 - val_loss: 0.5920 - val_acc: 0.7953 - val_categorical_accuracy: 0.7953\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.6227 - acc: 0.7815 - categorical_accuracy: 0.7815 - val_loss: 0.5735 - val_acc: 0.7974 - val_categorical_accuracy: 0.7974\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.6053 - acc: 0.7883 - categorical_accuracy: 0.7883 - val_loss: 0.5705 - val_acc: 0.8006 - val_categorical_accuracy: 0.8006\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.5856 - acc: 0.7943 - categorical_accuracy: 0.7943 - val_loss: 0.5617 - val_acc: 0.8067 - val_categorical_accuracy: 0.8067\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.5755 - acc: 0.7985 - categorical_accuracy: 0.7985 - val_loss: 0.5507 - val_acc: 0.8116 - val_categorical_accuracy: 0.8116\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.5580 - acc: 0.8039 - categorical_accuracy: 0.8039 - val_loss: 0.5544 - val_acc: 0.8087 - val_categorical_accuracy: 0.8087\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.5467 - acc: 0.8077 - categorical_accuracy: 0.8077 - val_loss: 0.5425 - val_acc: 0.8132 - val_categorical_accuracy: 0.8132\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.5358 - acc: 0.8125 - categorical_accuracy: 0.8125 - val_loss: 0.5192 - val_acc: 0.8247 - val_categorical_accuracy: 0.8247\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.5174 - acc: 0.8206 - categorical_accuracy: 0.8206 - val_loss: 0.5436 - val_acc: 0.8137 - val_categorical_accuracy: 0.8137\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.5143 - acc: 0.8202 - categorical_accuracy: 0.8202 - val_loss: 0.5249 - val_acc: 0.8221 - val_categorical_accuracy: 0.8221\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.5051 - acc: 0.8229 - categorical_accuracy: 0.8229 - val_loss: 0.5263 - val_acc: 0.8222 - val_categorical_accuracy: 0.8222\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.4917 - acc: 0.8282 - categorical_accuracy: 0.8282 - val_loss: 0.5125 - val_acc: 0.8261 - val_categorical_accuracy: 0.8261\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.4797 - acc: 0.8313 - categorical_accuracy: 0.8313 - val_loss: 0.5133 - val_acc: 0.8272 - val_categorical_accuracy: 0.8272\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.4703 - acc: 0.8368 - categorical_accuracy: 0.8368 - val_loss: 0.5077 - val_acc: 0.8289 - val_categorical_accuracy: 0.8289\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.4641 - acc: 0.8368 - categorical_accuracy: 0.8368 - val_loss: 0.5131 - val_acc: 0.8260 - val_categorical_accuracy: 0.8260\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.4564 - acc: 0.8386 - categorical_accuracy: 0.8386 - val_loss: 0.5041 - val_acc: 0.8272 - val_categorical_accuracy: 0.8272\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.4491 - acc: 0.8431 - categorical_accuracy: 0.8431 - val_loss: 0.5015 - val_acc: 0.8334 - val_categorical_accuracy: 0.8334\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.4388 - acc: 0.8457 - categorical_accuracy: 0.8457 - val_loss: 0.4998 - val_acc: 0.8290 - val_categorical_accuracy: 0.8290\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.4335 - acc: 0.8477 - categorical_accuracy: 0.8477 - val_loss: 0.4958 - val_acc: 0.8365 - val_categorical_accuracy: 0.8365\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.4278 - acc: 0.8486 - categorical_accuracy: 0.8486 - val_loss: 0.5146 - val_acc: 0.8299 - val_categorical_accuracy: 0.8299\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.4171 - acc: 0.8530 - categorical_accuracy: 0.8530 - val_loss: 0.4878 - val_acc: 0.8393 - val_categorical_accuracy: 0.8393\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.4159 - acc: 0.8562 - categorical_accuracy: 0.8562 - val_loss: 0.4751 - val_acc: 0.8420 - val_categorical_accuracy: 0.8420\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.4046 - acc: 0.8578 - categorical_accuracy: 0.8578 - val_loss: 0.4849 - val_acc: 0.8385 - val_categorical_accuracy: 0.8385\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.3959 - acc: 0.8597 - categorical_accuracy: 0.8597 - val_loss: 0.4748 - val_acc: 0.8437 - val_categorical_accuracy: 0.8437\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.3943 - acc: 0.8621 - categorical_accuracy: 0.8621 - val_loss: 0.4946 - val_acc: 0.8366 - val_categorical_accuracy: 0.8366\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.3850 - acc: 0.8658 - categorical_accuracy: 0.8658 - val_loss: 0.4798 - val_acc: 0.8381 - val_categorical_accuracy: 0.8381\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.3867 - acc: 0.8637 - categorical_accuracy: 0.8637 - val_loss: 0.4740 - val_acc: 0.8439 - val_categorical_accuracy: 0.8439\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.3716 - acc: 0.8692 - categorical_accuracy: 0.8692 - val_loss: 0.4748 - val_acc: 0.8443 - val_categorical_accuracy: 0.8443\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.3638 - acc: 0.8701 - categorical_accuracy: 0.8701 - val_loss: 0.4861 - val_acc: 0.8457 - val_categorical_accuracy: 0.8457\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.3663 - acc: 0.8685 - categorical_accuracy: 0.8685 - val_loss: 0.4676 - val_acc: 0.8511 - val_categorical_accuracy: 0.8511\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.3576 - acc: 0.8740 - categorical_accuracy: 0.8740 - val_loss: 0.4803 - val_acc: 0.8448 - val_categorical_accuracy: 0.8448\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.3554 - acc: 0.8747 - categorical_accuracy: 0.8747 - val_loss: 0.4613 - val_acc: 0.8498 - val_categorical_accuracy: 0.8498\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.3518 - acc: 0.8749 - categorical_accuracy: 0.8749 - val_loss: 0.4690 - val_acc: 0.8452 - val_categorical_accuracy: 0.8452\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.3413 - acc: 0.8780 - categorical_accuracy: 0.8780 - val_loss: 0.4719 - val_acc: 0.8502 - val_categorical_accuracy: 0.8502\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.3373 - acc: 0.8812 - categorical_accuracy: 0.8812 - val_loss: 0.4740 - val_acc: 0.8465 - val_categorical_accuracy: 0.8465\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.3372 - acc: 0.8809 - categorical_accuracy: 0.8809 - val_loss: 0.4897 - val_acc: 0.8465 - val_categorical_accuracy: 0.8465\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.3325 - acc: 0.8827 - categorical_accuracy: 0.8827 - val_loss: 0.4833 - val_acc: 0.8456 - val_categorical_accuracy: 0.8456\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.3255 - acc: 0.8839 - categorical_accuracy: 0.8839 - val_loss: 0.4892 - val_acc: 0.8430 - val_categorical_accuracy: 0.8430\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.3245 - acc: 0.8848 - categorical_accuracy: 0.8848 - val_loss: 0.4657 - val_acc: 0.8478 - val_categorical_accuracy: 0.8478\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.3203 - acc: 0.8862 - categorical_accuracy: 0.8862 - val_loss: 0.4946 - val_acc: 0.8436 - val_categorical_accuracy: 0.8436\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.3169 - acc: 0.8887 - categorical_accuracy: 0.8887 - val_loss: 0.4863 - val_acc: 0.8503 - val_categorical_accuracy: 0.8503\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.3137 - acc: 0.8892 - categorical_accuracy: 0.8892 - val_loss: 0.4801 - val_acc: 0.8475 - val_categorical_accuracy: 0.8475\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.3067 - acc: 0.8908 - categorical_accuracy: 0.8908 - val_loss: 0.4758 - val_acc: 0.8499 - val_categorical_accuracy: 0.8499\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.3033 - acc: 0.8932 - categorical_accuracy: 0.8932 - val_loss: 0.4784 - val_acc: 0.8510 - val_categorical_accuracy: 0.8510\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.3045 - acc: 0.8913 - categorical_accuracy: 0.8913 - val_loss: 0.4891 - val_acc: 0.8465 - val_categorical_accuracy: 0.8465\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.2978 - acc: 0.8946 - categorical_accuracy: 0.8946 - val_loss: 0.4831 - val_acc: 0.8514 - val_categorical_accuracy: 0.8514\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.2976 - acc: 0.8937 - categorical_accuracy: 0.8937 - val_loss: 0.4733 - val_acc: 0.8527 - val_categorical_accuracy: 0.8527\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.2963 - acc: 0.8942 - categorical_accuracy: 0.8942 - val_loss: 0.4835 - val_acc: 0.8515 - val_categorical_accuracy: 0.8515\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.2903 - acc: 0.8969 - categorical_accuracy: 0.8969 - val_loss: 0.4733 - val_acc: 0.8518 - val_categorical_accuracy: 0.8518\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.2901 - acc: 0.8965 - categorical_accuracy: 0.8965 - val_loss: 0.4811 - val_acc: 0.8505 - val_categorical_accuracy: 0.8505\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.2850 - acc: 0.8987 - categorical_accuracy: 0.8987 - val_loss: 0.4701 - val_acc: 0.8567 - val_categorical_accuracy: 0.8567\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.2765 - acc: 0.9020 - categorical_accuracy: 0.9020 - val_loss: 0.4805 - val_acc: 0.8547 - val_categorical_accuracy: 0.8547\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.2804 - acc: 0.9020 - categorical_accuracy: 0.9020 - val_loss: 0.4825 - val_acc: 0.8483 - val_categorical_accuracy: 0.8483\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.2718 - acc: 0.9040 - categorical_accuracy: 0.9040 - val_loss: 0.4685 - val_acc: 0.8571 - val_categorical_accuracy: 0.8571\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.2734 - acc: 0.9027 - categorical_accuracy: 0.9027 - val_loss: 0.4873 - val_acc: 0.8543 - val_categorical_accuracy: 0.8543\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.2701 - acc: 0.9041 - categorical_accuracy: 0.9041 - val_loss: 0.4714 - val_acc: 0.8554 - val_categorical_accuracy: 0.8554\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.2598 - acc: 0.9074 - categorical_accuracy: 0.9074 - val_loss: 0.4609 - val_acc: 0.8562 - val_categorical_accuracy: 0.8562\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.2667 - acc: 0.9048 - categorical_accuracy: 0.9048 - val_loss: 0.4656 - val_acc: 0.8588 - val_categorical_accuracy: 0.8588\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.2641 - acc: 0.9084 - categorical_accuracy: 0.9084 - val_loss: 0.4761 - val_acc: 0.8570 - val_categorical_accuracy: 0.8570\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.2614 - acc: 0.9074 - categorical_accuracy: 0.9074 - val_loss: 0.4684 - val_acc: 0.8575 - val_categorical_accuracy: 0.8575\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.2590 - acc: 0.9077 - categorical_accuracy: 0.9077 - val_loss: 0.4708 - val_acc: 0.8558 - val_categorical_accuracy: 0.8558\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.2555 - acc: 0.9084 - categorical_accuracy: 0.9084 - val_loss: 0.4804 - val_acc: 0.8546 - val_categorical_accuracy: 0.8546\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.2540 - acc: 0.9090 - categorical_accuracy: 0.9090 - val_loss: 0.4979 - val_acc: 0.8522 - val_categorical_accuracy: 0.8522\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2524 - acc: 0.9102 - categorical_accuracy: 0.9102 - val_loss: 0.4719 - val_acc: 0.8562 - val_categorical_accuracy: 0.8562\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2479 - acc: 0.9124 - categorical_accuracy: 0.9124 - val_loss: 0.5001 - val_acc: 0.8515 - val_categorical_accuracy: 0.8515\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.2482 - acc: 0.9114 - categorical_accuracy: 0.9114 - val_loss: 0.4635 - val_acc: 0.8588 - val_categorical_accuracy: 0.8588\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.2459 - acc: 0.9121 - categorical_accuracy: 0.9121 - val_loss: 0.4829 - val_acc: 0.8537 - val_categorical_accuracy: 0.8537\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.2439 - acc: 0.9133 - categorical_accuracy: 0.9133 - val_loss: 0.5091 - val_acc: 0.8506 - val_categorical_accuracy: 0.8506\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.2407 - acc: 0.9139 - categorical_accuracy: 0.9139 - val_loss: 0.4760 - val_acc: 0.8567 - val_categorical_accuracy: 0.8567\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.2393 - acc: 0.9161 - categorical_accuracy: 0.9161 - val_loss: 0.4916 - val_acc: 0.8533 - val_categorical_accuracy: 0.8533\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.2413 - acc: 0.9146 - categorical_accuracy: 0.9146 - val_loss: 0.4784 - val_acc: 0.8564 - val_categorical_accuracy: 0.8564\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.2378 - acc: 0.9145 - categorical_accuracy: 0.9145 - val_loss: 0.4817 - val_acc: 0.8568 - val_categorical_accuracy: 0.8568\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 21s 413us/step - loss: 0.2370 - acc: 0.9155 - categorical_accuracy: 0.9155 - val_loss: 0.4694 - val_acc: 0.8602 - val_categorical_accuracy: 0.8602\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 21s 430us/step - loss: 0.2300 - acc: 0.9185 - categorical_accuracy: 0.9185 - val_loss: 0.4859 - val_acc: 0.8563 - val_categorical_accuracy: 0.8563\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.2275 - acc: 0.9203 - categorical_accuracy: 0.9203 - val_loss: 0.4793 - val_acc: 0.8583 - val_categorical_accuracy: 0.8583\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2290 - acc: 0.9191 - categorical_accuracy: 0.9191 - val_loss: 0.4714 - val_acc: 0.8580 - val_categorical_accuracy: 0.8580\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2314 - acc: 0.9173 - categorical_accuracy: 0.9173 - val_loss: 0.4710 - val_acc: 0.8603 - val_categorical_accuracy: 0.8603\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.2253 - acc: 0.9195 - categorical_accuracy: 0.9195 - val_loss: 0.4860 - val_acc: 0.8578 - val_categorical_accuracy: 0.8578\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.2240 - acc: 0.9206 - categorical_accuracy: 0.9206 - val_loss: 0.4650 - val_acc: 0.8592 - val_categorical_accuracy: 0.8592\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.2235 - acc: 0.9211 - categorical_accuracy: 0.9211 - val_loss: 0.4755 - val_acc: 0.8613 - val_categorical_accuracy: 0.8613\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 21s 417us/step - loss: 0.2170 - acc: 0.9228 - categorical_accuracy: 0.9228 - val_loss: 0.4890 - val_acc: 0.8596 - val_categorical_accuracy: 0.8596\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.2203 - acc: 0.9218 - categorical_accuracy: 0.9218 - val_loss: 0.4742 - val_acc: 0.8612 - val_categorical_accuracy: 0.8612\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.2188 - acc: 0.9219 - categorical_accuracy: 0.9219 - val_loss: 0.4663 - val_acc: 0.8605 - val_categorical_accuracy: 0.8605\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 0.2118 - acc: 0.9248 - categorical_accuracy: 0.9248 - val_loss: 0.4728 - val_acc: 0.8618 - val_categorical_accuracy: 0.8618\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.2114 - acc: 0.9261 - categorical_accuracy: 0.9261 - val_loss: 0.4960 - val_acc: 0.8579 - val_categorical_accuracy: 0.8579\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.2117 - acc: 0.9250 - categorical_accuracy: 0.9250 - val_loss: 0.5096 - val_acc: 0.8592 - val_categorical_accuracy: 0.8592\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2066 - acc: 0.9272 - categorical_accuracy: 0.9272 - val_loss: 0.4768 - val_acc: 0.8621 - val_categorical_accuracy: 0.8621\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.2117 - acc: 0.9240 - categorical_accuracy: 0.9240 - val_loss: 0.4812 - val_acc: 0.8617 - val_categorical_accuracy: 0.8617\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.2043 - acc: 0.9280 - categorical_accuracy: 0.9280 - val_loss: 0.4852 - val_acc: 0.8637 - val_categorical_accuracy: 0.8637\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.2016 - acc: 0.9291 - categorical_accuracy: 0.9291 - val_loss: 0.5052 - val_acc: 0.8591 - val_categorical_accuracy: 0.8591\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.2049 - acc: 0.9274 - categorical_accuracy: 0.9274 - val_loss: 0.4762 - val_acc: 0.8610 - val_categorical_accuracy: 0.8610\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.2061 - acc: 0.9260 - categorical_accuracy: 0.9260 - val_loss: 0.4718 - val_acc: 0.8639 - val_categorical_accuracy: 0.8639\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.2017 - acc: 0.9288 - categorical_accuracy: 0.9288 - val_loss: 0.4763 - val_acc: 0.8616 - val_categorical_accuracy: 0.8616\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.2016 - acc: 0.9278 - categorical_accuracy: 0.9278 - val_loss: 0.4942 - val_acc: 0.8609 - val_categorical_accuracy: 0.8609\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.2028 - acc: 0.9301 - categorical_accuracy: 0.9301 - val_loss: 0.4848 - val_acc: 0.8638 - val_categorical_accuracy: 0.8638\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.2038 - acc: 0.9282 - categorical_accuracy: 0.9282 - val_loss: 0.4828 - val_acc: 0.8609 - val_categorical_accuracy: 0.8609\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 0.1974 - acc: 0.9302 - categorical_accuracy: 0.9302 - val_loss: 0.4846 - val_acc: 0.8617 - val_categorical_accuracy: 0.8617\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.1991 - acc: 0.9299 - categorical_accuracy: 0.9299 - val_loss: 0.4852 - val_acc: 0.8617 - val_categorical_accuracy: 0.8617\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1961 - acc: 0.9308 - categorical_accuracy: 0.9308 - val_loss: 0.5164 - val_acc: 0.8547 - val_categorical_accuracy: 0.8547\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.1954 - acc: 0.9303 - categorical_accuracy: 0.9303 - val_loss: 0.4884 - val_acc: 0.8607 - val_categorical_accuracy: 0.8607\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 0.1931 - acc: 0.9310 - categorical_accuracy: 0.9310 - val_loss: 0.4960 - val_acc: 0.8602 - val_categorical_accuracy: 0.8602\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.1882 - acc: 0.9323 - categorical_accuracy: 0.9323 - val_loss: 0.5019 - val_acc: 0.8588 - val_categorical_accuracy: 0.8588\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.1889 - acc: 0.9326 - categorical_accuracy: 0.9326 - val_loss: 0.4984 - val_acc: 0.8605 - val_categorical_accuracy: 0.8605\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.1890 - acc: 0.9334 - categorical_accuracy: 0.9334 - val_loss: 0.4780 - val_acc: 0.8633 - val_categorical_accuracy: 0.8633\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.1914 - acc: 0.9323 - categorical_accuracy: 0.9323 - val_loss: 0.4931 - val_acc: 0.8615 - val_categorical_accuracy: 0.8615\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.1897 - acc: 0.9323 - categorical_accuracy: 0.9323 - val_loss: 0.5029 - val_acc: 0.8570 - val_categorical_accuracy: 0.8570\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.1871 - acc: 0.9349 - categorical_accuracy: 0.9349 - val_loss: 0.5112 - val_acc: 0.8587 - val_categorical_accuracy: 0.8587\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.1930 - acc: 0.9317 - categorical_accuracy: 0.9317 - val_loss: 0.4954 - val_acc: 0.8597 - val_categorical_accuracy: 0.8597\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.1854 - acc: 0.9345 - categorical_accuracy: 0.9345 - val_loss: 0.4814 - val_acc: 0.8641 - val_categorical_accuracy: 0.8641\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1877 - acc: 0.9334 - categorical_accuracy: 0.9334 - val_loss: 0.4726 - val_acc: 0.8667 - val_categorical_accuracy: 0.8667\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1829 - acc: 0.9356 - categorical_accuracy: 0.9356 - val_loss: 0.4857 - val_acc: 0.8622 - val_categorical_accuracy: 0.8622\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1852 - acc: 0.9344 - categorical_accuracy: 0.9344 - val_loss: 0.4854 - val_acc: 0.8636 - val_categorical_accuracy: 0.8636\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.1775 - acc: 0.9370 - categorical_accuracy: 0.9370 - val_loss: 0.4944 - val_acc: 0.8633 - val_categorical_accuracy: 0.8633\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1825 - acc: 0.9352 - categorical_accuracy: 0.9352 - val_loss: 0.4974 - val_acc: 0.8631 - val_categorical_accuracy: 0.8631\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1785 - acc: 0.9366 - categorical_accuracy: 0.9366 - val_loss: 0.4892 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1795 - acc: 0.9377 - categorical_accuracy: 0.9377 - val_loss: 0.4852 - val_acc: 0.8634 - val_categorical_accuracy: 0.8634\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1763 - acc: 0.9373 - categorical_accuracy: 0.9373 - val_loss: 0.4986 - val_acc: 0.8630 - val_categorical_accuracy: 0.8630\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.1773 - acc: 0.9376 - categorical_accuracy: 0.9376 - val_loss: 0.5094 - val_acc: 0.8590 - val_categorical_accuracy: 0.8590\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.1750 - acc: 0.9387 - categorical_accuracy: 0.9387 - val_loss: 0.4932 - val_acc: 0.8636 - val_categorical_accuracy: 0.8636\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1788 - acc: 0.9371 - categorical_accuracy: 0.9371 - val_loss: 0.4833 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1756 - acc: 0.9376 - categorical_accuracy: 0.9376 - val_loss: 0.4792 - val_acc: 0.8674 - val_categorical_accuracy: 0.8674\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1727 - acc: 0.9395 - categorical_accuracy: 0.9395 - val_loss: 0.5123 - val_acc: 0.8592 - val_categorical_accuracy: 0.8592\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1754 - acc: 0.9381 - categorical_accuracy: 0.9381 - val_loss: 0.4911 - val_acc: 0.8648 - val_categorical_accuracy: 0.8648\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.1728 - acc: 0.9395 - categorical_accuracy: 0.9395 - val_loss: 0.5001 - val_acc: 0.8657 - val_categorical_accuracy: 0.8657\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1727 - acc: 0.9382 - categorical_accuracy: 0.9382 - val_loss: 0.4967 - val_acc: 0.8646 - val_categorical_accuracy: 0.8646\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1703 - acc: 0.9395 - categorical_accuracy: 0.9395 - val_loss: 0.5025 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1688 - acc: 0.9401 - categorical_accuracy: 0.9401 - val_loss: 0.5024 - val_acc: 0.8637 - val_categorical_accuracy: 0.8637\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.1723 - acc: 0.9400 - categorical_accuracy: 0.9400 - val_loss: 0.4812 - val_acc: 0.8661 - val_categorical_accuracy: 0.8661\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1657 - acc: 0.9425 - categorical_accuracy: 0.9425 - val_loss: 0.5176 - val_acc: 0.8620 - val_categorical_accuracy: 0.8620\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.1677 - acc: 0.9414 - categorical_accuracy: 0.9414 - val_loss: 0.4921 - val_acc: 0.8658 - val_categorical_accuracy: 0.8658\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 21s 418us/step - loss: 0.1649 - acc: 0.9425 - categorical_accuracy: 0.9425 - val_loss: 0.4944 - val_acc: 0.8664 - val_categorical_accuracy: 0.8664\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1650 - acc: 0.9416 - categorical_accuracy: 0.9416 - val_loss: 0.5068 - val_acc: 0.8659 - val_categorical_accuracy: 0.8659\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 0.1676 - acc: 0.9415 - categorical_accuracy: 0.9415 - val_loss: 0.4961 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.1617 - acc: 0.9416 - categorical_accuracy: 0.9416 - val_loss: 0.4844 - val_acc: 0.8697 - val_categorical_accuracy: 0.8697\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.1695 - acc: 0.9410 - categorical_accuracy: 0.9410 - val_loss: 0.4919 - val_acc: 0.8641 - val_categorical_accuracy: 0.8641\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.1609 - acc: 0.9430 - categorical_accuracy: 0.9430 - val_loss: 0.4888 - val_acc: 0.8676 - val_categorical_accuracy: 0.8676\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.1624 - acc: 0.9435 - categorical_accuracy: 0.9435 - val_loss: 0.4880 - val_acc: 0.8685 - val_categorical_accuracy: 0.8685\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1595 - acc: 0.9435 - categorical_accuracy: 0.9435 - val_loss: 0.4929 - val_acc: 0.8661 - val_categorical_accuracy: 0.8661\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.1654 - acc: 0.9433 - categorical_accuracy: 0.9433 - val_loss: 0.4844 - val_acc: 0.8656 - val_categorical_accuracy: 0.8656\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 0.1563 - acc: 0.9445 - categorical_accuracy: 0.9445 - val_loss: 0.5235 - val_acc: 0.8617 - val_categorical_accuracy: 0.8617\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.1557 - acc: 0.9446 - categorical_accuracy: 0.9446 - val_loss: 0.4959 - val_acc: 0.8688 - val_categorical_accuracy: 0.8688\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 0.1632 - acc: 0.9444 - categorical_accuracy: 0.9444 - val_loss: 0.4900 - val_acc: 0.8677 - val_categorical_accuracy: 0.8677\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.1562 - acc: 0.9446 - categorical_accuracy: 0.9446 - val_loss: 0.5013 - val_acc: 0.8680 - val_categorical_accuracy: 0.8680\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1599 - acc: 0.9429 - categorical_accuracy: 0.9429 - val_loss: 0.4984 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.1573 - acc: 0.9444 - categorical_accuracy: 0.9444 - val_loss: 0.4955 - val_acc: 0.8659 - val_categorical_accuracy: 0.8659\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.1558 - acc: 0.9450 - categorical_accuracy: 0.9450 - val_loss: 0.4911 - val_acc: 0.8723 - val_categorical_accuracy: 0.8723\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.1581 - acc: 0.9443 - categorical_accuracy: 0.9443 - val_loss: 0.4865 - val_acc: 0.8689 - val_categorical_accuracy: 0.8689\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1525 - acc: 0.9456 - categorical_accuracy: 0.9456 - val_loss: 0.5266 - val_acc: 0.8580 - val_categorical_accuracy: 0.8580\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.1575 - acc: 0.9450 - categorical_accuracy: 0.9450 - val_loss: 0.5074 - val_acc: 0.8636 - val_categorical_accuracy: 0.8636\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.1493 - acc: 0.9474 - categorical_accuracy: 0.9474 - val_loss: 0.5053 - val_acc: 0.8635 - val_categorical_accuracy: 0.8635\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.1537 - acc: 0.9474 - categorical_accuracy: 0.9474 - val_loss: 0.4952 - val_acc: 0.8659 - val_categorical_accuracy: 0.8659\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1532 - acc: 0.9458 - categorical_accuracy: 0.9458 - val_loss: 0.5037 - val_acc: 0.8645 - val_categorical_accuracy: 0.8645\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1493 - acc: 0.9488 - categorical_accuracy: 0.9488 - val_loss: 0.5003 - val_acc: 0.8681 - val_categorical_accuracy: 0.8681\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1523 - acc: 0.9467 - categorical_accuracy: 0.9467 - val_loss: 0.5104 - val_acc: 0.8628 - val_categorical_accuracy: 0.8628\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1544 - acc: 0.9460 - categorical_accuracy: 0.9460 - val_loss: 0.5127 - val_acc: 0.8636 - val_categorical_accuracy: 0.8636\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1539 - acc: 0.9463 - categorical_accuracy: 0.9463 - val_loss: 0.4893 - val_acc: 0.8712 - val_categorical_accuracy: 0.8712\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.1485 - acc: 0.9476 - categorical_accuracy: 0.9476 - val_loss: 0.5020 - val_acc: 0.8669 - val_categorical_accuracy: 0.8669\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.1505 - acc: 0.9467 - categorical_accuracy: 0.9467 - val_loss: 0.5139 - val_acc: 0.8618 - val_categorical_accuracy: 0.8618\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 0.1474 - acc: 0.9485 - categorical_accuracy: 0.9485 - val_loss: 0.4974 - val_acc: 0.8667 - val_categorical_accuracy: 0.8667\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.1464 - acc: 0.9491 - categorical_accuracy: 0.9491 - val_loss: 0.4994 - val_acc: 0.8676 - val_categorical_accuracy: 0.8676\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1499 - acc: 0.9473 - categorical_accuracy: 0.9473 - val_loss: 0.4979 - val_acc: 0.8686 - val_categorical_accuracy: 0.8686\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 0.1464 - acc: 0.9477 - categorical_accuracy: 0.9477 - val_loss: 0.5117 - val_acc: 0.8638 - val_categorical_accuracy: 0.8638\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.1456 - acc: 0.9483 - categorical_accuracy: 0.9483 - val_loss: 0.5235 - val_acc: 0.8629 - val_categorical_accuracy: 0.8629\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 0.1493 - acc: 0.9474 - categorical_accuracy: 0.9474 - val_loss: 0.5199 - val_acc: 0.8621 - val_categorical_accuracy: 0.8621\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1454 - acc: 0.9485 - categorical_accuracy: 0.9485 - val_loss: 0.5053 - val_acc: 0.8677 - val_categorical_accuracy: 0.8677\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1457 - acc: 0.9491 - categorical_accuracy: 0.9491 - val_loss: 0.4958 - val_acc: 0.8679 - val_categorical_accuracy: 0.8679\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 23s 453us/step - loss: 0.1469 - acc: 0.9487 - categorical_accuracy: 0.9487 - val_loss: 0.5041 - val_acc: 0.8648 - val_categorical_accuracy: 0.8648\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 23s 454us/step - loss: 0.1499 - acc: 0.9475 - categorical_accuracy: 0.9475 - val_loss: 0.5140 - val_acc: 0.8635 - val_categorical_accuracy: 0.8635\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 0.1408 - acc: 0.9512 - categorical_accuracy: 0.9512 - val_loss: 0.5253 - val_acc: 0.8650 - val_categorical_accuracy: 0.8650\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1439 - acc: 0.9503 - categorical_accuracy: 0.9503 - val_loss: 0.5185 - val_acc: 0.8619 - val_categorical_accuracy: 0.8619\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1456 - acc: 0.9494 - categorical_accuracy: 0.9494 - val_loss: 0.5051 - val_acc: 0.8701 - val_categorical_accuracy: 0.8701\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.1405 - acc: 0.9505 - categorical_accuracy: 0.9505 - val_loss: 0.5151 - val_acc: 0.8678 - val_categorical_accuracy: 0.8678\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1444 - acc: 0.9487 - categorical_accuracy: 0.9487 - val_loss: 0.5005 - val_acc: 0.8671 - val_categorical_accuracy: 0.8671\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.1429 - acc: 0.9503 - categorical_accuracy: 0.9503 - val_loss: 0.5149 - val_acc: 0.8652 - val_categorical_accuracy: 0.8652\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.1401 - acc: 0.9503 - categorical_accuracy: 0.9503 - val_loss: 0.5103 - val_acc: 0.8687 - val_categorical_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.1433 - acc: 0.9498 - categorical_accuracy: 0.9498 - val_loss: 0.5507 - val_acc: 0.8603 - val_categorical_accuracy: 0.8603\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1460 - acc: 0.9488 - categorical_accuracy: 0.9488 - val_loss: 0.5098 - val_acc: 0.8646 - val_categorical_accuracy: 0.8646\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.1362 - acc: 0.9526 - categorical_accuracy: 0.9526 - val_loss: 0.4999 - val_acc: 0.8672 - val_categorical_accuracy: 0.8672\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1358 - acc: 0.9523 - categorical_accuracy: 0.9523 - val_loss: 0.5151 - val_acc: 0.8679 - val_categorical_accuracy: 0.8679\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.1397 - acc: 0.9510 - categorical_accuracy: 0.9510 - val_loss: 0.4984 - val_acc: 0.8686 - val_categorical_accuracy: 0.8686\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.1343 - acc: 0.9540 - categorical_accuracy: 0.9540 - val_loss: 0.5163 - val_acc: 0.8655 - val_categorical_accuracy: 0.8655\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1363 - acc: 0.9519 - categorical_accuracy: 0.9519 - val_loss: 0.5141 - val_acc: 0.8675 - val_categorical_accuracy: 0.8675\n",
            "10000/10000 [==============================] - 1s 108us/step\n",
            "정답률= 0.8675  / loss= 0.514133557856083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXSmlwoQGulJKhQkNdKWUChP/HwJ3rAZISO2HAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJsJZ0BtjTISzoDfGmAhnQW+MMRHu/wN9KrJpyOXBjAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}